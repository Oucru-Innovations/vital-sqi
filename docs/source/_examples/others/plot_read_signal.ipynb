{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Exploiting pandas!!\n\nThis example....\n\nSee more notes at the end.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load data\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Generic\nimport os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Scipy\nfrom scipy.stats import skew\nfrom scipy.stats import kurtosis\n\n# vitalSQI\nfrom vital_sqi.data.signal_io import ECG_reader\nfrom vital_sqi.dataset import load_ppg, load_ecg\n\n# ----------------------------\n# Load data\n# ----------------------------\n# Filepath\nfilepath = '../../tests/test_data'\nfilename = 'example.edf'\n\n# Load\ndata = ECG_reader(os.path.join(filepath, filename), 'edf')\n# data = load_ecg()\n\n# The attributes!\nprint(data)\nprint(data.signals)\nprint(data.sampling_rate)\nprint(data.wave_type)\nprint(data.sqis)\nprint(data.info)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Formatting\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# ----------------------------\n# Pandas\n# ----------------------------\n# Questions:\n# Could we exploit pandas?\n# Will it have any limitation?\n\n# Display (shows timedelta aligned)\npd.Timedelta.__str__ = lambda x: x._repr_base('all')\n\n# ----------------------\n# Format data\n# ----------------------\n# Load DataFrame\nsignals = pd.DataFrame(data.signals)\n\n# Include column with index\nsignals = signals.reset_index()\n\n# .. note: We are assuming that the data signals index has been\n#          recorded every fs no matter whether the patient moved,\n#          the device was disconnected and connected again, ...\n# Create timedelta\nsignals['timedelta'] = \\\n    pd.to_timedelta(signals.index / data.sampling_rate, unit='s')\n\n# Create datetimes (if needed)\n#signals['date'] = pd.to_datetime(data.start_datetime)\n#signals['date']+= pd.to_timedelta(signals.timedelta)\n\n# Set the timedelta index (keep numeric index too)\nsignals = signals.set_index('timedelta')\n\n# Rename column to avoid confusion\nsignals = signals.rename(columns={'index': 'idx'})\n\n# Show\nprint(\"\\nSignals:\")\nprint(signals)\n\n# Plot\nfig, axes = plt.subplots(nrows=2, ncols=1)\naxes = axes.flatten()\n\nsignals[0].plot(ax=axes[0])\nsignals[1].plot(ax=axes[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Preprocessing\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lets trim the first/last 5 minutes\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# -------------------------\n# Trim first/last 5 minutes\n# -------------------------\n# Offset\noffset = pd.Timedelta(minutes=5)\n\n# Indexes\nidxs = (signals.index > offset) & \\\n       (signals.index < signals.index[-1] - offset)\n\n# Filter\nsignals = signals[idxs]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lets resample the data\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Implement!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lets imput missing data\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Implement!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lets do tappering??\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Implement!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lets show the preprocessed signals\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Show\nprint(\"\\nPreprocessing:\")\nprint(signals)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Compute SQIs\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lets first see how the windows look like\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Implement!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lets define our own SQI function.\n\n.. note: This should be the real focus and strength of this\n         package, to have a series of sqi techniques very\n         easy to compute. Also it would be great if they can\n         be made compatible with pandas.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def own(x):\n    return np.random.randint(100)\n\n# .. note: What if it is a complex SQI that requires first\n#          to compute the peaks and then apply some numpy\n#          functions?\n\n# from vital_sqi.sqi.standard_sqi import msq_sqi\n\n# The msq_sqi uses a PeakDetector (although at the moment\n# it is missing the library so it breaks). When included,\n# it raises a weird warning but returns a value."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lets compute the SQIs\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# ---------------------\n# Compute SQIs\n# ---------------------\n# Group by 30s segments\nsqis = signals \\\n    .groupby(pd.Grouper(freq='30s')) \\\n    .agg({'idx': ['first', 'last'],\n          0: [skew, kurtosis, own],\n          1: [skew, kurtosis, own]})\n\n\n# .. note: We are assuming that the whole signal has been\n#          read in one chunk. This will not work if using\n#          batches, will window ids be necessary?\n# Add window id (if needed)\nsqis['w'] = np.arange(sqis.shape[0])\n\n# Show\nprint(\"\\nSQIs (all):\")\n#print(sqis)\nsqis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lets apply some signal quality rules\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# ---------------------\n# Apply SQI Rules\n# ---------------------\n\n# Apply random rule\nsqis['keep'] = np.random.choice(a=[False, True], size=(sqis.shape[0],))\n\n# Create basic rule\ncriteria = list(zip(*[\n    (sqis[0]['skew'].between(-2.9, -2.6), True),\n    (sqis[0]['skew'].between(4, 5), True)\n]))\n\n# Apply rule (default False)\nsqis['keep'] = np.select(criteria[0], criteria[1], False)\n\n# Keep all\n#sqis['keep'] = True\n\n# Keep only valid\nsqis = sqis[sqis.keep]\n\n# Show\nprint(\"\\nSQIs (valid):\")\nsqis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Lets go back to raw data\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lets extract the valid windows from the original signal\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# -------------------------------------\n# Extract windows from original signals\n# -------------------------------------\n# .. note: This might be fragile as it is not really using\n#          the index but the position. Anyways, the index\n#          column is just incremental isn't? Or am I missing\n#          special conditions when this might not happen?\n#\n# .. note: Could it be done more efficiently?\n#\n# .. note: We could include the window ids if needed. This could\n#          help linking the quality indexes stored in sqis.csv\n#          and the valid sections of the signal stored in the\n#          signals.csv file.\n#\n# Keep slices and concatenate\nslices = [signals.iloc[start:stop, :] for start, stop\n    in zip(sqis['idx']['first'],  sqis['idx']['last'])]\n\n# Concatenate only valid sections\nresult = pd.concat(slices)\n\n# Show\nprint(\"\\nSignals (for valid sqis)\")\nresult"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lets plot the result\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Create figure\nfig, axes = plt.subplots(nrows=2, ncols=1)\naxes = axes.flatten()\n\n# Plot\nresult[0].plot(ax=axes[0])\nresult[1].plot(ax=axes[1])\n\n# Adjust layout\nplt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Further analysis (other tutorial)\n\nNow that we have selected those sections in which the signal\nquality is appropriate. We can do further analysis, we can\nfind the peaks to identify the heart rate, we can describe\nthe windows statistically, ....\n\n\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Show\nplt.show()\n\n\n\n#\n#.. warning:: Should we use TimeInterval indexes for windows?\n#\n#.. warning:: Generalising rules:\n#\n#             https://stackoverflow.com/questions/50098025/mapping-ranges-of-values-in-pandas-dataframe\n#\n#.. warning:: This is a very basic example and might fail when using\n#             the reading in batches function from pandas. In such\n#             scenario, consider using a map reduce approach, which\n#             should not require many changes anyways.#\n#\n#             https://pythonspeed.com/articles/chunking-pandas/\n#\n#.. warning:: Useful to filter periods in which value is constant,\n#             maybe due to lost of connection or something similar.#\n#\n#             https://stackoverflow.com/questions/55271735/pandas-finding-start-end-values-of-consecutive-indexes-in-a-pandas-dataframe\n#             https://stackoverflow.com/questions/62361446/python-dataframe-get-index-start-and-end-of-successive-values\n#"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}